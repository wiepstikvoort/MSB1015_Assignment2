---
title: __Assignment_2_MSB1015__
author: "Wiep Stikvoort"
date: "October 13, 2019"
output: html_notebook
---
# __Creating a Partial Least Squares (PLS) regression model for the prediction of boiling points__ 
#### i6092796
#### MSB1015 Scientific Programming
When there is a reference to README.md file in the repository, you can find the information via: https://github.com/wiepstikvoort/MSB1015_Assignment2/blob/master/README.md  
Firstly, the libraries needed for the loading of the data, and for the computations to create the regression model need to be installed and loaded.      
      
```{r setup, echo = FALSE, warning = FALSE, message = FALSE}
# If the packages that are called inside the install.packages function are not yet installed on your computer, then please uncomment the line to do so
# install.packages(c('rJava', 'rcdk', 'pls', 'WikidataQueryServiceR', 'caTools', 'ggplot2'));

library(rJava)
library(rcdk)
library(pls)
library(WikidataQueryServiceR)
library(caTools)
library(ggplot2)
```

## __Alkanes and their boiling points__
### __Loading and processing of the data__
The data can now be loaded from WikiData using SPARQL. The query retrieves alkanes that have a boiling point in wikidata (please see the README.md file in the repository for more information on the query).
``` {r chunk query, echo = FALSE}
query <- query_wikidata('SELECT DISTINCT ?comp ?compLabel ?bp ?bpUnit ?bpUnitLabel ?CC
WHERE {   
?comp wdt:P31/wdt:P279* wd:Q41581 ;       
wdt:P233 ?CC  ;
p:P2102 [ ps:P2102 ?bp ;  
psv:P2102/wikibase:quantityUnit  ?bpUnit         ] .  
SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en". } }')
```
However, not all boiling points are in the same unit. After converting the boiling points that are in Fahrenheit or Celsius to Kelvin, the data can be checked. To check whether there are no more strange values, such as divergent units, in the dataset, a plot is created. This plot should show that all points are somewhat in the same range of values. 

```{r chunk functions and conversions, echo = FALSE}
# the following functions check whether a value has the unit of Fahrenheit or Celsius. If so, the functions insert the boiling point in kelvin inside the data for boiling points. 
fahrenheit_kelvin <- function(fahrenheit) {
  kelvin <- (fahrenheit + 459.67) * (5/9)
  return(kelvin)
}
celsius_kelvin <- function(celcius) {
  kelvin <- celcius + 293.15
  return(kelvin)
}

# the for loop checks all boiling points with the conversion functions described above. If a boiling point is converted to kelvin, the unit of the boiling point is also set to 'kelvin'. 
for (i in 1:length(query$bpUnitLabel)) {
  if(query$bpUnitLabel[i] == 'degree Celsius'){
      query$bp[i] <- celsius_kelvin(query$bp[i])
      query$bpUnitLabel[i] <- 'kelvin'
      }
  else if (query$bpUnitLabel[i] == 'degree Fahrenheit'){
     query$bp[i] <- fahrenheit_kelvin(query$bp[i])
     query$bpUnitLabel[i] <- 'kelvin'
  }
}

# plotting of the processed data
plot.default(query$bp, main = 'The index number of the alkane \nset out against the boiling point', xlab = 'Index number alkane', ylab = 'Boiling point (in K)')

```
As can be seen in the graph above there is a nice distribution of boiling points. There do not seem to be any divergent values in the data. 

### __SMILES and descriptors__
The data is split into test and training set. 80% of the data is used for the training set, the other 20% will then logically be part of the test set. 
```{r chunk splitting test and training, echo = FALSE}
data <- sort(sample(nrow(query), nrow(query)*.8))
training_set<-query[data,]

#creating test data set by not selecting the output row values
test_set<-query[-data,]
```
Chemical properties, descriptors, of the alkanes are needed to base the PLS model on. The SMILES (Simplified Molecular-Input Line-Entry System) of the alkanes were needed to find and calculate the descriptors. The classes used for these descriptors are discussed in the README.md file in the repository. 
```{r chunk parsing smiles and retrieving descriptors, echo = FALSE}
# the parse.smiles function creates IAtomContainer objects out of SMILES. Kekulise = TRUE disables the function to parse incorrect SMILES. So only correct SMILES are parsed. 
parsed_smiles <- parse.smiles(training_set$CC, kekulise=TRUE)

descNames <- c(
'org.openscience.cdk.qsar.descriptors.molecular.FragmentComplexityDescriptor',
'org.openscience.cdk.qsar.descriptors.molecular.APolDescriptor',
'org.openscience.cdk.qsar.descriptors.molecular.WienerNumbersDescriptor',
'org.openscience.cdk.qsar.descriptors.molecular.MDEDescriptor',
'org.openscience.cdk.qsar.descriptors.molecular.AtomCountDescriptor')

descs <- eval.desc(parsed_smiles, descNames)
training <- cbind(training_set, descs)

```
### __Creating the PLS model__
The descriptors and processed data are now within a data frame, from which can be worked to create the prediction model.  The function plsr (from the pls package) was used to create the model. The model can be visualized in a graph, as shown below. The x axis depicts the measured data, so the true boiling points, and the y axis depicts the predicted boiling points based on the model.
The model needs to be accurate, yet as simple as possible. The number of components can play a role here. To see how many components the model needs, a graph where the number of components are set out against the Root Mean Square Error of Prediction (RMSEP), as well as the number of components set out against R^2, can help. 

``` {r chunk creating pls model, echo = FALSE}

model <- plsr(bp ~ WPATH  + fragC + apol + WPATH + WPOL + MDEC.12 + nAtom, data = training, validation = "LOO") 

plot(model, asp = 1, line = TRUE, xlab = "measured (in K)", ylab = "predicted (in K)")
plot(RMSEP(model, estimate = "CV"), main = "Number of components per model \nset out against their RMSEP (of boiling points)")
plot(model, "validation", val.type = "R2", main = "Number of components per model \nset out against their R^2")

```
The RMSEP and R^2 graphs both show that 3 components yields a model that would not improve anymore by adding more components. The RMSEP does not decline anymore, and the R^2 does not increase anymore. Therefore a model with 3 components is chosen to work with.  

### __Testing the PLS model__  
The input for the PLS model needs to have the same descriptors as were used in the creation of the model. Therefore, the descriptors, based on the SMILES, were retrieved for the test set as well. This was used as input for the testing of the model. The model uses the descriptors to predict the boiling points of the alkanes.  
The table shows the RMSEP per number of components. The graph below shows the same values. Just as the training set, the test set shows that 3 components is the optimal number for this model, based on accuracy and simplicity. 
``` {r chunk testing the pls model, echo = FALSE}
parsed_smiles_test <- parse.smiles(test_set$CC, kekulise = TRUE)
descs_test <- eval.desc(parsed_smiles_test, descNames)

test <- cbind(test_set, descs_test)
error <- RMSEP(model, newdata = test)
print(error)

plot(error, main = "The number of components per model \nset out against the RMSEP for the testset")
```
To predict the boiling points based on the descriptors, the function predict() is used. The values retrieved from the prediction were set out against the true data, and shown in the graph below. The points are in an approximately straight line, meaning that the predicted values and true values are very close together, and that their are no biases as to where the boiling points are predicted best (low or high boiling points). 
```{r chunk using the model to predict, echo = FALSE}
predict <- predict(model, ncomp = 3, newdata = test) # 
plot(predict, test_set$bp, ylab = "Data testset (in K)", xlab = "Predicted values for testset (in K)", main = "Predicted data set out against actual data")
corcoef <- cor(predict, test_set$bp)
```
The correlation coefficient between the true boiling points and the predicted boiling points (for this specific training and test set) is:
``` {r, echo = FALSE}
print(corcoef)
```
# ________________________________________________
## __Amino acids and their masses__
### __Loading and processing of the data__
To check the reproducibility of the code, another model was created by almost copying the code for the PLS model that predicts the alkane boiling points (further explanation is given in the README.md file in the repository). All graphs and tables were reproduced, based on the same theory and same function, but different data. All graphs below were based on the amino acid data. 

``` {r chunk query for aa, echo = FALSE, message = FALSE}
# the query for the amino acids is not much different from the query for the alkanes, except for the fact that mass is now requested instead of boiling points

query_amino_acids <- query_wikidata('SELECT DISTINCT ?comp ?compLabel ?mass ?massUnit ?massUnitLabel ?CC
WHERE {   
?comp wdt:P31/wdt:P279* wd:Q8066 ;       
wdt:P233 ?CC  ;
p:P2067 [ ps:P2067 ?mass ;  
psv:P2067/wikibase:quantityUnit  ?massUnit         ] .  
SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en". } }')
```
The amino acids (aa) and their masses were loaded from WikiData using SPARQL. All compound masses were expressed in the atomic mass unit (which is equivalent to g/mol), so no need for conversions. 
``` {r chunk, echo = FALSE}
plot.default(query_amino_acids$mass, main = 'The index number of the amino acid \nset out against the boiling point', xlab = 'Index number amino acid', ylab = 'Mass (AMU)')
```
The graph seemed to show some outliers. However, after a small literature research, these amino acids turned out to simply be a little heavier than most other amino acids. 

### __SMILES and descriptors__
```{r chunk splitting test and training aa, echo = FALSE}
data_aa <- sort(sample(nrow(query_amino_acids), nrow(query_amino_acids)*.8))
training_set_aa<-query_amino_acids[data_aa,]

#creating test data set by not selecting the output row values
test_set_aa<-query_amino_acids[-data_aa,]
```

The same methods were implemented as were described and used for the creation of the alkane boiling points PLS model, unless otherwise specified. The one main thing that was changed were the variable names to prevent confusion. 
```{r chunk parsing smiles and retrieving descriptors for aa, echo = FALSE}
parsed_smiles_aa <- parse.smiles(training_set_aa$CC, kekulise=TRUE) # changes it into a format IAtomContainer

descNames <- c(
'org.openscience.cdk.qsar.descriptors.molecular.FragmentComplexityDescriptor',
'org.openscience.cdk.qsar.descriptors.molecular.APolDescriptor',
'org.openscience.cdk.qsar.descriptors.molecular.WienerNumbersDescriptor',
'org.openscience.cdk.qsar.descriptors.molecular.MDEDescriptor',
'org.openscience.cdk.qsar.descriptors.molecular.AtomCountDescriptor')

descs_aa <- eval.desc(parsed_smiles_aa, descNames)
training_aa <- cbind(training_set_aa, descs_aa)
```
### __Creating the PLS model__
The model is visualized in the same manner as is shown for the alkane model:

``` {r chunk creation of pls model for aa, echo = FALSE}
model_aa <- plsr(mass ~ WPATH + fragC + apol + WPATH + WPOL + MDEC.12 + nAtom, data = training_aa, validation = "LOO") 

plot(model_aa, asp = 1, line = TRUE, xlab = "measured (in AMU)", ylab = "predicted (in AMU)" )

plot(RMSEP(model_aa, estimate = "CV"),  main = "Number of components per model \nset out against their RMSEP (of mass)")
plot(model_aa, "validation", val.type = "R2", main = "Number of components per model \nset out against their R^2")

```
The R^2 graph shows an increase until 5 components are included in the model. The same can be seen from the RMSEP graph, the RMSEP decreases until 5 components. This is different than the 3 components used for the alkane model. This can probably be attributed to the fact that the descriptors used for both models were chosen, based on the idea to predict boiling points from chemical properties, and not to predict their masses. 

### __Testing the PLS model__ 
```{r chunk testing the pls model for aa, echo = FALSE}
parsed_smiles_test_aa <- parse.smiles(test_set_aa$CC, kekulise = TRUE)
descs_test_aa <- eval.desc(parsed_smiles_test_aa, descNames)

test_aa <- cbind(test_set_aa, descs_test_aa)
error_aa <- RMSEP(model_aa, newdata = test_aa)
plot(error_aa)
print(error_aa, main = "The number of components per model \nset out against the RMSEP for the testset")
```

The graph showing the predicted masses and the true masses of the amino acids, shown below, shows a linear behavior. The points do not allign as neatly as they did for the alkane boiling points model however. This can be due to the fact that the dataset is smaller, or because there are better descriptors to be used to create this PLS model.
```{r chunk using the pls model to predict masses for aa, echo = FALSE}

predict_aa <- predict(model_aa, ncomp = 5, newdata = test_aa) # 
plot(predict_aa, test_set_aa$mass,  ylab = "Data testset (in AMU)", xlab = "Predicted values for testset (in AMU)", main = "Predicted data set out against actual data")
```
The correlation coefficient between the true masses and the predicted masses (for this specific training and test set) is:
``` {r chunk correlation coefficient aa, echo = FALSE}
corcoef_aa <- cor(predict_aa, test_set_aa$mass)
print(corcoef_aa)

```
# ________________________________________________
### __Conclusion__
Using SPARQL and R a PLS model can be created to predict the boiling points of alkanes. The code was easily reused. A different dataset with boiling points would have been a better fit for this assignment, to be able to compare the models better. However, to find out whether a different dataset could be implemented easily, this was not necessary. 
The correlation coefficients and the values (and thus the graphs) for the RMSEP can change when the script is rerun. This depends on which compounds are randomly distributed over the training and test sets. If most compounds with low boiling points are in the training set, and all compounds with high boiling points in the test set for example, the model has trouble predicting with the same accuracy as when the boiling points are evenly distributed over training and test set. 